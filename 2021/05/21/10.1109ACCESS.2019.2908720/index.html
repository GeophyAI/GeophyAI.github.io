<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans SC:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Courier New:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.geophyai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Wavelet Deep Neural Network for Stripe Noise Removal文献翻译">
<meta property="og:type" content="article">
<meta property="og:title" content="Wavelet Deep Neural Network for Stripe Noise Removal">
<meta property="og:url" content="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/index.html">
<meta property="og:site_name" content="GeophyAI">
<meta property="og:description" content="Wavelet Deep Neural Network for Stripe Noise Removal文献翻译">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/fig01.png">
<meta property="og:image" content="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/fig02.png">
<meta property="og:image" content="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/fig03.png">
<meta property="article:published_time" content="2021-05-21T03:10:46.000Z">
<meta property="article:modified_time" content="2021-05-21T03:10:46.000Z">
<meta property="article:author" content="shaowinw">
<meta property="article:tag" content="深度学习与计算地球物理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/fig01.png">

<link rel="canonical" href="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Wavelet Deep Neural Network for Stripe Noise Removal | GeophyAI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">GeophyAI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Python与地球物理数据处理</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="shaowinw">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeophyAI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Wavelet Deep Neural Network for Stripe Noise Removal
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-21 11:10:46" itemprop="dateCreated datePublished" datetime="2021-05-21T11:10:46+08:00">2021-05-21</time>
            </span>


	
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">文献翻译</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/05/21/10.1109ACCESS.2019.2908720/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/05/21/10.1109ACCESS.2019.2908720/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">Wavelet Deep Neural Network for Stripe Noise Removal文献翻译</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>基于小波深度神经网络的条纹噪声去除<br>
原文地址：<a href="https://ieeexplore.ieee.org/document/8678750/authors#authors">https://ieeexplore.ieee.org/document/8678750/authors#authors</a><br>
doi：10.1109/ACCESS.2019.2908720</p>
<h1>ABSRTACT</h1>
<p>在红外成像系统中，条纹噪声会严重影响图像质量。现有的去条纹算法在噪声抑制、细节保持和实时性等方面仍存在较大的困难，阻碍了其在光谱成像和信号处理领域的应用。为了解决这一问题，本文从变换域的角度提出了一种新颖的小波深层神经网络，它充分考虑了条纹噪声的固有特性和不同小波子带系数之间的互补信息，以较低的计算量准确估计噪声。此外，还定义了一种特殊的方向正则化器，使场景细节与条纹噪声分离更彻底，细节恢复更准确。大量的模拟和真实数据实验表明，本文提出的方法在定量和定性评价上都优于几种经典的去条带方法。</p>
<h1>INTRODUCTION</h1>
<p>红外图像在遥感、医学诊断、视觉跟踪、物联网传感等领域有着广泛的应用<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="A. Jara et al., ‘‘Joint de-blurring and nonuniformity correction method for infrared microscopy imaging,’’ Infr. Phys. Technol., vol. 90, pp. 199–206, May 2018.
">[1]</span></a></sup><sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Y. Cao and Y. Li, ‘‘Strip non-uniformity correction in uncooled long-wave infrared focal plane array based on noise source characterization,’’ Opt. Commun., vol. 339, pp. 236–242, Mar. 2015.
">[2]</span></a></sup><sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Y. Huang, C. He, H. Fang, and X. Wang, ‘‘Iteratively reweighted unidirectional variational model for stripe non-uniformity correction,’’ Infr. Phys. Technol., vol. 75, pp. 107–116, Mar. 2016.
">[3]</span></a></sup><sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="C. Chen, X. Liu, H.-H. Chen, M. Li, and L. Zhao, ‘‘A rear-end collision risk evaluation and control scheme using a Bayesian network model,’’ IEEE Trans. Intell. Transp. Syst., vol. 20, no. 1, pp. 264–284, Jan. 2019.
">[4]</span></a></sup>。由于硬件制作工艺的限制，探测器对同一辐照度的光电响应可能不完全一致，导致观测结果上叠加了固定条纹噪声，严重降低了红外成像系统的灵敏度<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="R. Lai, G. Yue, and G. Zhang, ‘‘Total variation based neural network regression for nonuniformity correction of infrared images,’’ Symmetry, vol. 10, no. 5, p. 157, 2018.
">[5]</span></a></sup><sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="R. Lai, J. Guan, Y. Yang, and A. Xiong, ‘‘Spatiotemporal adaptive nonuniformity correction based on BTV regularization,’’ IEEE Access, vol. 7, pp. 753–762, 2019.
">[6]</span></a></sup><sup id="fnref:7"><a href="#fn:7" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="K. Liang, C.Yang, L. Peng, and B. Zhou, ‘‘Nonuniformity correction based on focal plane array temperature in uncooled long-wave infrared cameras without a shutter,’’ Appl. Opt., vol. 56, no. 4, pp. 884–889, 2017.
">[7]</span></a></sup>。因此，在去除条纹噪声的同时保持真实场景的结构是非常关键的。条纹噪声衰减模型可以表示为<br>
$$y(i, j)=x(i, j)+n(i, j)$$<br>
其中$y(i,j)$、$x(i, j)$和$n(i, j)$分别表示观测响应、理想响应和由位于$(i,j)$的探测器所产生的条纹状噪声。<br>
近年来，基于不同框架的算法被提出用于条纹噪声去噪。大体可以将这些方法分为三种：（1）基于先验信息类方法；（2）基于统计学方法；（3）深度学习方法。<sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="X. Jian, R. Lu, Q. Guo, and G.-P. Wang, ‘‘Single image non-uniformity correction using compressive sensing,’’ Infr. Phys. Technol., vol. 76, pp. 360–364, May 2016.
">[8]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S. Rong, H. Zhou, D. Zhao, K. Cheng, K. Qian, and H. Qin, ‘‘Infrared fix pattern noise reduction method based on shearlet transform,’’ Infr. Phys. Technol., vol. 91, pp. 243–249, Jun. 2018.
">[9]</span></a></sup>基于先验信息方法，主要有块匹配（block-matching）和3D滤波（BM3D）<sup id="fnref:10"><a href="#fn:10" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="K. Dabov, A. Foi, and K. Egiazarian, ‘‘Video denoising by sparse 3D transform-domain collaborative filtering,’’ in Proc. Eur. Signal Process. Conf., Poznan, Poland, Sep. 2007, pp. 145–149.
">[10]</span></a></sup>、TV(Total variation)<sup id="fnref:11"><a href="#fn:11" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="L. I. Rudin, S. Osher, and E. Fatemi, ‘‘Nonlinear total variation based noise removal algorithms,’’ Phys. D, Nonlinear Phenomena, vol. 60, nos. 1–4, pp. 259–268, 1992.
">[11]</span></a></sup>，导向滤波(guided filter, GF)<sup id="fnref:12"><a href="#fn:12" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="K. He, J. Sun, and X. Tang, ‘‘Guided image filtering,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 6, pp. 1397–1409, Jun. 2013.
">[12]</span></a></sup>，$non-local means(NLM)$滤波<sup id="fnref:13"><a href="#fn:13" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Li and C. Y. Suen, ‘‘A novel non-local means image denoising method based on grey theory,’’ Pattern Recognit., vol. 49, pp. 237–248, Jan. 2016.
VOLUME 7, 2019
">[13]</span></a></sup>以及低秩正则化<sup id="fnref:14"><a href="#fn:14" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Y. Chang, L. Yan, T. Wu, and S. Zhong, ‘‘Remote sensing image stripe noise removal: From image decomposition perspective,’’ IEEE Trans. Geosci. Remote Sens., vol. 54, no. 12, pp. 7018–7031, Dec. 2016.
">[14]</span></a></sup>等，但是这些方法在消除条纹噪声时也会无差别地消除图片的细节信息，如此一来可能会在输出图片中产生假象。基于统计学的方法，例如$histogram equalization(MHE)$<sup id="fnref:15"><a href="#fn:15" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Y. Tendero, J. Gilles, S. Landeau, and J. M. Morel, ‘‘Efficient single image non-uniformity correction algorithm,’’ Proc. SPIE, vol. 7834, Oct. 2010, Art. no. 78340E.
">[15]</span></a></sup>等，在相邻列中引入冗余信息来消除条纹噪声，这种方法只适用于较弱的条纹噪声。当前，基于深度学习的方法被广泛应用于图像处理领域，均表现出非凡的效果。Kuang等提出了三层条纹噪声消除卷积神经网络$SNRCNN$，直接将条纹去噪视为图像去噪和超分辨率<sup id="fnref:19"><a href="#fn:19" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S. G. Chang, B. Yu, and M. Vetterli, ‘‘Adaptive wavelet thresholding for image denoising and compression,’’ IEEE Trans. Image Process., vol. 9, no. 9, pp. 1532–1546, Sep. 2000.
">[19]</span></a></sup>，但并没有考虑条纹噪声的具体特性，因此很难在去除条纹噪声的同时保留高频细节信息。为了消除这一限制，He等提出了具有更大感受野的$DLSNUC$模型来达到更好的消除效果<sup id="fnref:17"><a href="#fn:17" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Z. He, Y. Cao, Y. Dong, J. Yang, Y. Cao, and C.-L. Tisse, ‘‘Single-imagebased nonuniformity correction of uncooled long-wave infrared detectors: A deep-learning approach,’’ Appl. Opt., vol. 57, no. 18, pp. D155–D164, 2018.
">[17]</span></a></sup>。Xiao等提出$ICSRN$，其将CNN中的局部信息和全局信息结合起来以更好地保留边缘信息。但是仍然很难处理强条纹噪声。总结来讲，现有的深度学习去条纹方法只提取了图像在时间域的信息而忽视了其在时频域的冗余信息，因此限制了条纹去噪算法的应用。<br>
过去一段时期内，基于转换域的图像处理方法被广泛应用<sup id="fnref:19"><a href="#fn:19" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S. G. Chang, B. Yu, and M. Vetterli, ‘‘Adaptive wavelet thresholding for image denoising and compression,’’ IEEE Trans. Image Process., vol. 9, no. 9, pp. 1532–1546, Sep. 2000.
">[19]</span></a></sup><sup id="fnref:20"><a href="#fn:20" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="A. L. da Cunha, J. Zhou, and M. N. Do, ‘‘The nonsubsampled contourlet transform: Theory, design, and applications,’’ IEEETrans. Image Process., vol. 15, no. 10, pp. 3089–3101, Oct. 2006.
">[20]</span></a></sup>。在此基础上，Huang等提出了超分辨率网络来预测图像在小波域的缺失细节信息<sup id="fnref:21"><a href="#fn:21" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Huang, R. He, Z. Sun, and T. Tan, ‘‘Wavelet-SRNet: A wavelet-based CNN for multi-scale face super resolution,’’ in Proc. IEEE Conf. CVPR, Honolulu, HI, USA, Oct. 2017, pp. 1689–1697.
">[21]</span></a></sup>；Kang等利用$Contourlet$变换分析图像特征，在CT图像去噪方面取得了较好的效果<sup id="fnref:22"><a href="#fn:22" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="E. Kang, J. Min, and J. C. Ye, ‘‘A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction,’’ Med. Phys., vol. 44, no. 10, pp. e360–e375, 2017.
">[22]</span></a></sup>。受这些方法的启发，我们提出了基于小波的深度神经网络去除条纹噪声（SNRWDNN），其挖掘了图像在小波域的特征并且将多个频带的信息作为有效补充来更好的去除条纹噪声。本文主要创新点和贡献如下：</p>
<ol>
<li>引入小波域条纹去噪神经网络，其能够自适应的估计噪声强度和分布。</li>
<li>提出方向正则化器来避免模型产生不规则条纹噪声，并更好地恢复场景细节信息。</li>
<li>利用小波分解将输入图像变为一系列四分之一大小的系数，以提升计算效率并提升去噪效果。<br>
本文其余部分组织结构如下：在Section2中，我们分析了条纹噪声在小波域的表现形式。Section3详细阐述了SNRWDNN的实现细节。为了更好地展示本文所提方法的效果，模拟数据和真实数据实验均用于分析（Section4）。Section5为结论。</li>
</ol>
<h1>PROPERTY ANALYSIS OF STRIPE NOISE</h1>
<p><img src="/2021/05/21/10.1109ACCESS.2019.2908720/fig01.png" alt="fig01"><br>
为了准确地估计图像中含有的条纹噪声，关键是要挖掘出条纹噪声分量的属性并使用合理的方式描述它们。如文献<sup id="fnref:23"><a href="#fn:23" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="Y. Chen, T.-Z. Huang, L.-J. Deng, X.-L. Zhao, and M. Wang, ‘‘Group sparsity based regularization model for remote sensing image stripe noise removal,’’ Neurocomputing, vol. 267, pp. 95–106, Dec. 2017.
">[23]</span></a></sup>中所述，条纹噪声具有明显的方向属性，这一属性有利于去噪过程中图像细节和噪声分量的分离。图1展示了含条纹噪声图像的水平梯度和垂向梯度。从结果中我们可以看出，条纹噪声明显存在于水平梯度中，并且严重影响着垂直方向的图像细节信息。与之相反的是，垂向梯度中的条纹噪声分量表现出较好的平滑性质，因此对图像细节影响不大。基于以上简单的分析，可以基于不同方向梯度信息来从含噪图像中去除条纹噪声并可能保留图像的结构信息。<br>
<img src="/2021/05/21/10.1109ACCESS.2019.2908720/fig02.png" alt="fig02"><br>
$Harr$离散小波变换(HDWT)具有提取图像水平方向、垂直方向、对角方向高频信息、以及保留低频结构信息的能力。本文中，$HDWT$被用于提取条纹噪声的梯度信息并更彻底地从条纹噪声中区分场景细节信息。$HDWT$的结果如图2所示。可以明显看出条纹噪声在近似系数(cA)和水平系数(cH)中有明显的响应，与之相对应的，垂向系数(cV)和对角系数(cD)则主要描述了场景的细节信息。总结来讲，不同子频带的补充性信息有助于在去除条纹噪声的同时保留图像的细节信息。</p>
<h1>THE PROPOSED SRNWDNN MODEL</h1>
<p>在这一章节中，我们将详细介绍提出的$SNRWDNN$模型结构，然后深入讨论所设计的方向损失函数对于保留图像纹理细节的重要性，最后给出训练策略。</p>
<h2 id="A-网络结构">A.网络结构</h2>
<p><img src="/2021/05/21/10.1109ACCESS.2019.2908720/fig03.png" alt="fig03"><br>
$SNRWDNN$网络结构如图3所示。与现有的基于深度学习的条纹噪声去除方法不同，我们将条带噪声去除视为小波域的变换系数预测问题。$SNRWDNN$方法包括三个步骤：$HDWT$、小波系数预测和$Haar$离散小波逆变换$IHDWT$。首先，利用$HDWT$得到反映条纹噪声固有特性的四个子带系数。然后将这些系数串联成一个输入张量，送入小波系数预测网络，估计条纹分量，然后将输入张量与估计的条纹分量跳转连接，进行噪声消除，产生去条纹系数。值得注意的是，级联操作融合了不同子带中的信息，并保持了它们之间的一致性。最后，利用$IHDWT$对估计系数进行反变换，重建空间域去噪后结果。通过这种策略，我们提出的网络可以利用条纹的方向特性来抑制噪声，同时减少细节损失。小波系数预测网络由M层具有残差连接的卷积层构成，其中所有卷积滤波器共享大小为$3 \times3$、$stride$为1的卷积核。另外，采用零填充的方法使每个特征映射与输入张量保持相同的大小。除了最后一层输出4通道条纹分量外，每个卷积层的核数被设置为64。此外，将前一卷积层的输出输入到校正线性单元（ReLU）激活函数中进行非线性映射。由于SNRWDNN的输入和输出非常相似，我们采用了残差学习方法，使训练更加稳定、快速和精确。小波分解中的下采样操作有效地扩大了感受野，有利于场景细节的恢复<sup id="fnref:25"><a href="#fn:25" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Chen, X. He, L. Qing, S. Xiong, and T. Q. Nguyen, ‘‘DPW-SDNet: Dual pixel-wavelet domain deep CNNs for soft decoding of JPEG-compressed images,’’ presented at the IEEE Conf. CVPR, Salt Lake City, UT, USA, 2018.
">[25]</span></a></sup>，同时其减少了计算复杂性。此外，小波分解大大降低了计算复杂度。</p>
<h2 id="B-方向小波损失函数">B.方向小波损失函数</h2>
<p>当前基于深度学习的铜像处理任务通常关注于最小化均方误差目标函数<sup id="fnref:26"><a href="#fn:26" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="C. Ledig et al., ‘‘Photo-realistic single image super-resolution using a generative adversarial network,’’ in Proc. IEEE Conf. CVPR, Honolulu, HI, USA, Jul. 2017, pp. 105–114.
">[26]</span></a></sup>。本文延续前人<sup id="fnref:21"><a href="#fn:21" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Huang, R. He, Z. Sun, and T. Tan, ‘‘Wavelet-SRNet: A wavelet-based CNN for multi-scale face super resolution,’’ in Proc. IEEE Conf. CVPR, Honolulu, HI, USA, Oct. 2017, pp. 1689–1697.
">[21]</span></a></sup><sup id="fnref:25"><a href="#fn:25" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Chen, X. He, L. Qing, S. Xiong, and T. Q. Nguyen, ‘‘DPW-SDNet: Dual pixel-wavelet domain deep CNNs for soft decoding of JPEG-compressed images,’’ presented at the IEEE Conf. CVPR, Salt Lake City, UT, USA, 2018.
">[25]</span></a></sup>工作，引入小波均方误差损失来处理小波域的条纹噪声去除任务。小波均方误差被定义为<br>
$$L_W=\mid\mid cA- \overline{cA} \mid\mid_2^2+\mid\mid cV- \overline{cV} \mid\mid+\mid\mid cH- \overline{cH} \mid\mid+\mid\mid cD- \overline{cD} \mid\mid \tag{2}$$<br>
其中，$\mid\mid·\mid\mid_2^2$表示$L2$范数，$cA$,$cV$,$cH$,$cD$分别代表真实图像的近似系数、水平系数、垂向系数和对角系数，$\overline{cA}$,$\overline{cV}$,$\overline{cH}$,$\overline{cD}$，分别表示它们的预测值。<br>
从局部角度看，单个条纹内的像素强度在较窄的范围内变化，这意味着条纹的沿条纹方向上具有良好的平滑性。为了更好地估计条纹噪声，我们通过最小化条纹相关子带中条纹分量方向的部分差异来描述其平滑程度<sup id="fnref:27"><a href="#fn:27" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="X. Liu, X. Lu, H. Shen, Q. Yuan, Y. Jiao, and L. Zhang, ‘‘Stripe noise separation and removal in remote sensing images by consideration of the global sparsity and local variational properties,’’ IEEE Trans. Geosci. Remote Sens., vol. 54, no. 5, pp. 3049–3060, May 2016.
">[27]</span></a></sup>。为此，构造方向化正则器<br>
$$L_D=\mid\mid \nabla S_{cA} \mid\mid_2^2+\mid\mid \nabla S_{cH}\mid\mid_2^2\tag{3}$$<br>
其中$\nabla$代表沿条纹方向的偏微分算子。$S_{cA}$和$S_{cH}$表示$cA$和$cH$子带的条纹分量。<br>
最后，所提出的方向小波损失函数为<br>
$$Loss = L_W+\lambda L_D \tag{4}$$<br>
其中，$\lambda$为控制方向损失的常量。</p>
<a id="more"></a>
<details><summary>参考文献</summary>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Jara et al., ‘‘Joint de-blurring and nonuniformity correction method for infrared microscopy imaging,’’ Infr. Phys. Technol., vol. 90, pp. 199–206, May 2018.<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Cao and Y. Li, ‘‘Strip non-uniformity correction in uncooled long-wave infrared focal plane array based on noise source characterization,’’ Opt. Commun., vol. 339, pp. 236–242, Mar. 2015.<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Huang, C. He, H. Fang, and X. Wang, ‘‘Iteratively reweighted unidirectional variational model for stripe non-uniformity correction,’’ Infr. Phys. Technol., vol. 75, pp. 107–116, Mar. 2016.<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C. Chen, X. Liu, H.-H. Chen, M. Li, and L. Zhao, ‘‘A rear-end collision risk evaluation and control scheme using a Bayesian network model,’’ IEEE Trans. Intell. Transp. Syst., vol. 20, no. 1, pp. 264–284, Jan. 2019.<a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Lai, G. Yue, and G. Zhang, ‘‘Total variation based neural network regression for nonuniformity correction of infrared images,’’ Symmetry, vol. 10, no. 5, p. 157, 2018.<a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Lai, J. Guan, Y. Yang, and A. Xiong, ‘‘Spatiotemporal adaptive nonuniformity correction based on BTV regularization,’’ IEEE Access, vol. 7, pp. 753–762, 2019.<a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Liang, C.Yang, L. Peng, and B. Zhou, ‘‘Nonuniformity correction based on focal plane array temperature in uncooled long-wave infrared cameras without a shutter,’’ Appl. Opt., vol. 56, no. 4, pp. 884–889, 2017.<a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">X. Jian, R. Lu, Q. Guo, and G.-P. Wang, ‘‘Single image non-uniformity correction using compressive sensing,’’ Infr. Phys. Technol., vol. 76, pp. 360–364, May 2016.<a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S. Rong, H. Zhou, D. Zhao, K. Cheng, K. Qian, and H. Qin, ‘‘Infrared fix pattern noise reduction method based on shearlet transform,’’ Infr. Phys. Technol., vol. 91, pp. 243–249, Jun. 2018.<a href="#fnref:9" rev="footnote"> ↩</a></span></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">10.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Dabov, A. Foi, and K. Egiazarian, ‘‘Video denoising by sparse 3D transform-domain collaborative filtering,’’ in Proc. Eur. Signal Process. Conf., Poznan, Poland, Sep. 2007, pp. 145–149.<a href="#fnref:10" rev="footnote"> ↩</a></span></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">11.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">L. I. Rudin, S. Osher, and E. Fatemi, ‘‘Nonlinear total variation based noise removal algorithms,’’ Phys. D, Nonlinear Phenomena, vol. 60, nos. 1–4, pp. 259–268, 1992.<a href="#fnref:11" rev="footnote"> ↩</a></span></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">12.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. He, J. Sun, and X. Tang, ‘‘Guided image filtering,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 6, pp. 1397–1409, Jun. 2013.<a href="#fnref:12" rev="footnote"> ↩</a></span></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">13.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Li and C. Y. Suen, ‘‘A novel non-local means image denoising method based on grey theory,’’ Pattern Recognit., vol. 49, pp. 237–248, Jan. 2016.
VOLUME 7, 2019<a href="#fnref:13" rev="footnote"> ↩</a></span></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">14.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Chang, L. Yan, T. Wu, and S. Zhong, ‘‘Remote sensing image stripe noise removal: From image decomposition perspective,’’ IEEE Trans. Geosci. Remote Sens., vol. 54, no. 12, pp. 7018–7031, Dec. 2016.<a href="#fnref:14" rev="footnote"> ↩</a></span></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">15.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Tendero, J. Gilles, S. Landeau, and J. M. Morel, ‘‘Efficient single image non-uniformity correction algorithm,’’ Proc. SPIE, vol. 7834, Oct. 2010, Art. no. 78340E.<a href="#fnref:15" rev="footnote"> ↩</a></span></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">16.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">X. Kuang, X. Sui, Q. Chen, and G. Gu, ‘‘Single infrared image stripe noise removal using deep convolutional networks,’’ IEEEPhoton. J., vol. 9, no. 4, Aug. 2017, Art. no. 3900913.<a href="#fnref:16" rev="footnote"> ↩</a></span></li><li id="fn:17"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">17.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Z. He, Y. Cao, Y. Dong, J. Yang, Y. Cao, and C.-L. Tisse, ‘‘Single-imagebased nonuniformity correction of uncooled long-wave infrared detectors: A deep-learning approach,’’ Appl. Opt., vol. 57, no. 18, pp. D155–D164, 2018.<a href="#fnref:17" rev="footnote"> ↩</a></span></li><li id="fn:18"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">18.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">P. Xiao, Y. Guo, and P. Zhuang, ‘‘Removing stripe noise from infrared cloud images via deep convolutional networks,’’ IEEE Photon. J., vol. 10, no. 4, Aug. 2018, Art. no. 7801114.<a href="#fnref:18" rev="footnote"> ↩</a></span></li><li id="fn:19"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">19.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S. G. Chang, B. Yu, and M. Vetterli, ‘‘Adaptive wavelet thresholding for image denoising and compression,’’ IEEE Trans. Image Process., vol. 9, no. 9, pp. 1532–1546, Sep. 2000.<a href="#fnref:19" rev="footnote"> ↩</a></span></li><li id="fn:20"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">20.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. L. da Cunha, J. Zhou, and M. N. Do, ‘‘The nonsubsampled contourlet transform: Theory, design, and applications,’’ IEEETrans. Image Process., vol. 15, no. 10, pp. 3089–3101, Oct. 2006.<a href="#fnref:20" rev="footnote"> ↩</a></span></li><li id="fn:21"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">21.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Huang, R. He, Z. Sun, and T. Tan, ‘‘Wavelet-SRNet: A wavelet-based CNN for multi-scale face super resolution,’’ in Proc. IEEE Conf. CVPR, Honolulu, HI, USA, Oct. 2017, pp. 1689–1697.<a href="#fnref:21" rev="footnote"> ↩</a></span></li><li id="fn:22"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">22.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">E. Kang, J. Min, and J. C. Ye, ‘‘A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction,’’ Med. Phys., vol. 44, no. 10, pp. e360–e375, 2017.<a href="#fnref:22" rev="footnote"> ↩</a></span></li><li id="fn:23"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">23.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Chen, T.-Z. Huang, L.-J. Deng, X.-L. Zhao, and M. Wang, ‘‘Group sparsity based regularization model for remote sensing image stripe noise removal,’’ Neurocomputing, vol. 267, pp. 95–106, Dec. 2017.<a href="#fnref:23" rev="footnote"> ↩</a></span></li><li id="fn:24"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">24.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">B. L. Lai and L. W. Chang, ‘‘Adaptive data hiding for images based on harr discrete wavelet transform,’’ in Advances in Image and Video Technology (Lecture Notes in Computer Science), vol. 4319. Berlin, Germany: Springer, 2006, pp. 1085–1093.<a href="#fnref:24" rev="footnote"> ↩</a></span></li><li id="fn:25"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">25.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Chen, X. He, L. Qing, S. Xiong, and T. Q. Nguyen, ‘‘DPW-SDNet: Dual pixel-wavelet domain deep CNNs for soft decoding of JPEG-compressed images,’’ presented at the IEEE Conf. CVPR, Salt Lake City, UT, USA, 2018.<a href="#fnref:25" rev="footnote"> ↩</a></span></li><li id="fn:26"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">26.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C. Ledig et al., ‘‘Photo-realistic single image super-resolution using a generative adversarial network,’’ in Proc. IEEE Conf. CVPR, Honolulu, HI, USA, Jul. 2017, pp. 105–114.<a href="#fnref:26" rev="footnote"> ↩</a></span></li><li id="fn:27"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">27.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">X. Liu, X. Lu, H. Shen, Q. Yuan, Y. Jiao, and L. Zhang, ‘‘Stripe noise separation and removal in remote sensing images by consideration of the global sparsity and local variational properties,’’ IEEE Trans. Geosci. Remote Sens., vol. 54, no. 5, pp. 3049–3060, May 2016.<a href="#fnref:27" rev="footnote"> ↩</a></span></li><li id="fn:28"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">28.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">W. Luo, J. Li, W. Xu, and J. Yang, ‘‘Learning sparse features in convolutional neural networks for image classification,’’ in Proc. Int. Conf. Intell. Sci. Big Data Eng., Suzhou, China, 2015, pp. 29–38.<a href="#fnref:28" rev="footnote"> ↩</a></span></li><li id="fn:29"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">29.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Simonyan and A. Zisserman. (2014). ‘‘Very deep convolutional networks for large-scale image recognition.’’ [^Online]:. Available: https:// arxiv.org/abs/1409.1556<a href="#fnref:29" rev="footnote"> ↩</a></span></li><li id="fn:30"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">30.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, ‘‘Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising,’’ IEEE Trans. Image Process., vol. 26, no. 7, pp. 3142–3155, Jul. 2017.<a href="#fnref:30" rev="footnote"> ↩</a></span></li><li id="fn:31"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">31.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D. Graziotin and P. Abrahamsson, ‘‘A Web-based modeling tool for the SEMAT essence theory of software engineering,’’ J. Open Res. Softw., to be published. doi: 10.5334/jors.ad.<a href="#fnref:31" rev="footnote"> ↩</a></span></li><li id="fn:32"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">32.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D. P. Kingma and J. Ba. (2014). ‘‘Adam: A method for stochastic optimization.’’ [^Online]:. Available: https://arxiv.org/abs/1412.6980<a href="#fnref:32" rev="footnote"> ↩</a></span></li><li id="fn:33"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">33.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Kim, J. K. Lee, and K. M. Lee, ‘‘Accurate image super-resolution using very deep convolutional networks,’’ in Proc. IEEE Conf. CVPR, Las Vegas, NV, USA, Jun. 2016, pp. 1646–1654.<a href="#fnref:33" rev="footnote"> ↩</a></span></li><li id="fn:34"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">34.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, ‘‘Image quality assessment: From error visibility to structural similarity,’’ IEEE Trans. Image Process., vol. 13, no. 4, pp. 600–612, Apr. 2004.<a href="#fnref:34" rev="footnote"> ↩</a></span></li><li id="fn:35"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">35.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Cao, M. Y. Yang, and C.-L. Tisse, ‘‘Effective strip noise removal for low-textured infrared images based on 1-D guided filtering,’’ IEEE Trans. Circuits Syst. Video Technol., vol. 26, no. 12, pp. 2176–2188, Dec. 2016.<a href="#fnref:35" rev="footnote"> ↩</a></span></li><li id="fn:36"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">36.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">N. Liu, L. Wan, Y. Zhang, T. Zhou, H. Huo, and T. Fang, ‘‘Exploiting convolutional neural networks with deeply local description for remote sensing image classification,’’ IEEE Access, vol. 6, pp. 11215–11228, 2018.<a href="#fnref:36" rev="footnote"> ↩</a></span></li><li id="fn:37"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">37.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Z. Jin et al., ‘‘EEG classification using sparse Bayesian extreme learning machine for brain–computer interface,’’ Neural Comput. Appl., to be published. doi: 10.1007/s00521-018-3735-3.<a href="#fnref:37" rev="footnote"> ↩</a></span></li><li id="fn:38"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">38.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">G. Zhou et al., ‘‘Linked component analysis from matrices to high-order tensors: Applications to biomedical data,’’ Proc. IEEE, vol. 104, no. 2, pp. 310–331, Feb. 2016.<a href="#fnref:38" rev="footnote"> ↩</a></span></li><li id="fn:39"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">39.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Lai, Y. Mo, Z. Liu, and J. Guan, ‘‘Local and nonlocal steering kernel weighted total variation model for image denoising,’’ Symmetry, vol. 11, no. 3, p. 329, 2019.<a href="#fnref:39" rev="footnote"> ↩</a></span></li><li id="fn:40"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">40.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, ‘‘MobileNetV2: Inverted residuals and linear bottlenecks,’’ in Proc. IEEE
Conf. Comput. Vis. Pattern Recognit., Salt Lake City, UT, USA, Jun. 2018, pp. 4510–4520.<a href="#fnref:40" rev="footnote"> ↩</a></span></li><li id="fn:41"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">41.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">W.-Q. Lim, ‘‘The discrete shearlet transform: A new directional transform and compactly supported shearlet frames,’’ IEEE Trans. Image Process., vol. 19, no. 5, pp. 1166–1180, May 2010.<a href="#fnref:41" rev="footnote"> ↩</a></span></li></ol></div></div></details><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>shaowinw
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/" title="Wavelet Deep Neural Network for Stripe Noise Removal">http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9C%B0%E7%90%83%E7%89%A9%E7%90%86/" rel="tag"> <i class="fa fa-tag"></i> 深度学习与计算地球物理</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/05/14/10.1016j.jcp.2018.10.045_b/" rel="prev" title="Physics-informed neural networks:Translation Part II">
      <i class="fa fa-chevron-left"></i> Physics-informed neural networks:Translation Part II
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/05/31/ITPS_Radon644~645/" rel="next" title="Radon变换">
      Radon变换 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text">ABSRTACT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">2.</span> <span class="nav-text">INTRODUCTION</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">3.</span> <span class="nav-text">PROPERTY ANALYSIS OF STRIPE NOISE</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">4.</span> <span class="nav-text">THE PROPOSED SRNWDNN MODEL</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#A-网络结构"><span class="nav-number">4.1.</span> <span class="nav-text">A.网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#B-方向小波损失函数"><span class="nav-number">4.2.</span> <span class="nav-text">B.方向小波损失函数</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">shaowinw</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">鲁ICP备20023201号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shaowinw</span>
</div>



        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://blog.geophyai.com/2021/05/21/10.1109ACCESS.2019.2908720/',]
      });
      });
  </script>

<script src="../js/src/av-min.js"></script>
<script src="../js/src/valine.min.js"></script>
<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/gh//AshinWang/SimpleValine/SimpleValine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xGkAfNjiLy2iAFwuv2Itmye6-gzGzoHsz',
      appKey     : 'IGOUrFEiKTeXfsDJwsmNLMnd',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
