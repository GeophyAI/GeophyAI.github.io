<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans SC:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Courier New:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.geophyai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Physics-informed neural networks翻译Part I">
<meta property="og:type" content="article">
<meta property="og:title" content="Physics-informed neural networks:Translation Part I">
<meta property="og:url" content="http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/index.html">
<meta property="og:site_name" content="GeophyAI">
<meta property="og:description" content="Physics-informed neural networks翻译Part I">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-05-07T03:10:46.000Z">
<meta property="article:modified_time" content="2021-05-07T03:10:46.000Z">
<meta property="article:author" content="shaowinw">
<meta property="article:tag" content="深度学习与计算地球物理">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Physics-informed neural networks:Translation Part I | GeophyAI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">GeophyAI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能与地球物理数据处理</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="shaowinw">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeophyAI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Physics-informed neural networks:Translation Part I
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-07 11:10:46" itemprop="dateCreated datePublished" datetime="2021-05-07T11:10:46+08:00">2021-05-07</time>
            </span>


	
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">文献翻译</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/05/07/10.1016j.jcp.2018.10.045_a/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/05/07/10.1016j.jcp.2018.10.045_a/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">Physics-informed neural networks翻译Part I</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>原文地址：<a href="https://www.sciencedirect.com/science/article/pii/S0021999118307125" target="_blank" rel="noopener">PINN：深度学习框架下求解含有非线性偏微分方程的正问题、反问题</a><br>
doi:<a href="http://sci-hub.ren/10.1016/j.jcp.2018.10.045" target="_blank" rel="noopener">10.1016/j.jcp.2018.10.045</a></p>
<h1>ABSTRACT</h1>
<p>本文介绍了PINN（Physics-informed neural networks，物理信息神经网络），其能够在解决监督学习任务的同时遵守由一般的非线性偏微分方程描述的物理约束。在这项工作中，我们主要从数据驱动解和偏微分方程的数据驱动解两方面探讨。根据可用数据的性质和排列（nature and arrangement），我们设计了两种不同类型的算法，即连续时间模型和离散时间模型。第一类模型形成了一族数据高效(data-efficient)的时空函数逼近器（spatio-temporal function approximators），而后一类模型能以任意精度的隐式Runge-Kutta时间递推格式（with unlimited number of stages）。通过流体、量子力学、反应扩散系统和非线性浅水波的传播等一系列经典问题，证明了该框架的有效性。</p>
<h1>Introduction</h1>
<p>随着可用数据量和计算资源的爆炸式增长，机器学习与数据挖掘的最新成果在不同领域的应用产生了变革性影响，流入图像识别<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classifification with deep convolutional neural networks, in: Advances in Neural Information Processing Systems, 2012, pp. 1097–1105.
">[1]</span></a></sup>、认知科学<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="B.M. Lake, R. Salakhutdinov, J.B. Tenenbaum, Human-level concept learning through probabilistic program induction, Science 350 (2015) 1332–1338.
">[2]</span></a></sup>、基因组学<sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="B. Alipanahi, A. Delong, M.T. Weirauch, B.J. Frey, Predicting the sequence specifificities of DNA- and RNA-binding proteins by deep learning, Nat. Biotechnol. 33 (2015) 831–838. 
">[3]</span></a></sup>等。然而，在分析复杂的物理、生物或工程系统的过程中，数据采集的成本往往过高，有时我们不得不使用有限的信息作出决策。在这种小数据环境下，绝大多数最先进的机器学习技术（如深度/卷积/递归神经网络）缺乏鲁棒性，无法保证收敛性。<br>
乍一看，训练一个神经网络，使其能够从几个可能是高维的输入和输出中学习到非线性映射是非常幼稚的。在许多物理和生物系统建模相关的案例中，往往存在有大量的先验知识，而这些知识还没有应用于现有的机器学习中。假设它是控制系统随时间变化的动力学物理定律，或一些已经经过经验验证的规则或其他领域的专业知识，这些先验信息可以作为正则化约束，将解限制在可以接受的范围内（例如，在不可压缩流体中，舍弃任何违背质量守恒定律的不现实的流动解）。将这种结构化信息编码为学习算法会放大算法所看到的数据中的信息含量，使其能够快速地向正确方向收敛，并且即使只有少数训练数据也能获得较好的泛化性。<br>
近期许多研究<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Inferring solutions of differential equations using noisy multi-fifidelity data, J. Comput. Phys. 335 (2017) 736–746.
">[4]</span></a></sup><sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.
">[5]</span></a></sup><sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Owhadi, Bayesian numerical homogenization, Multiscale Model. Simul. 13 (2015) 812–828.
">[6]</span></a></sup>已经展示了如何利用结构化先验信息构建数据高效和物理可靠（physical-informed）的模型。这里，我们利用高斯过程回归（Gaussian Process Regression）<sup id="fnref:7"><a href="#fn:7" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="C.E. Rasmussen, C.K. Williams, Gaussian Processes for Machine Learning, vol. 1, MIT Press, Cambridge, 2006.
">[7]</span></a></sup>设计了一个适合于给定线性算子的函数表示，其能够准确推断解并为多个数学物理问题提供不精确的解。在推理和系统辨识的背景下，Raissi 等人<sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Numerical Gaussian processes for time-dependent and non-linear partial differential equations, 2017, arXiv: 1703.10230.
">[8]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.
">[9]</span></a></sup>在后续研究中提出了非线性问题的推广。尽管高斯过程在编码先验信息时具有灵活性和数学优雅性，但其对非线性问题的处理有两个重要的限制。首先，在<sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Numerical Gaussian processes for time-dependent and non-linear partial differential equations, 2017, arXiv: 1703.10230.
">[8]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.
">[9]</span></a></sup>中，作者必须在时间上对任何非线性项进行局部线性化，从而限制了所提出方法在离散时域的适用性，并损害了它们在强非线性状态下预测的准确性。其次，高斯过程回归的贝叶斯性质有一定的先验假设，这些假设可能限制模型的表达能力，并产生鲁棒性/脆性（robustness/brittleness）问题，特别是对于非线性问题的处理<sup id="fnref:10"><a href="#fn:10" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="H. Owhadi, C. Scovel, T. Sullivan, et al., Brittleness of Bayesian inference under fifinite information in a continuous world, Electron. J. Stat. 9 (2015) 1–79.
">[10]</span></a></sup>。</p>
<h1>Problem setup</h1>
<p>在这项工作中，我们采取了一种不同的方法：利用深度神经网络和它们众所周知的作为普适函数逼近器的能力<sup id="fnref:11"><a href="#fn:11" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366.
">[11]</span></a></sup>。在这种情况下，我们可以直接处理非线性问题，而无需任何先验假设，线性化，或局部时间递推。我们利用自动微分技术的最新发展<sup id="fnref:12"><a href="#fn:12" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="A.G. Baydin, B.A. Pearlmutter, A.A. Radul, J.M. Siskind, Automatic differentiation in machine learning: a survey, 2015, arXiv:1502.05767.
">[12]</span></a></sup>——这是科学计算中最有用但可能利用不足的技术之一——根据输入坐标和模型参数对神经网络进行微分，以获得物理可靠的神经网络。这类神经网络被约束为遵守任何对称性、不变性或守恒原理，这些原理源于控制观测数据的物理定律，如一般的时间相关和非线性偏微分方程所模拟的那样。这种简单而强大的结构使我们能够解决计算科学中的一大类问题，并引入了一种潜在的变革性技术，从而开发出新的数据高效和物理可靠的学习机，新的偏微分方程数值解算器，以及用于模型反演和系统辨识的数据驱动方法。<br>
为此，我们的手稿分为两部分，旨在介绍我们在两大类问题背景下的发展：数据驱动的偏微分方程解和数据驱动的偏微分方程求解。论文相关的代码和数据集地址<a href="https://github%20.com%20/maziarraissi%20/PINNs">Github</a>。在这项工作中，我们只使用了相对简单的深度前馈神经网络结构，其具有双曲正切激活函数，并且没有额外的正则化（例如，L1/L2惩罚、Dropout等）。手稿中的每个数值例子都附有关于我们所采用的神经网络结构的详细讨论，以及关于其训练过程的详细信息（例如优化器、学习率等）。最后，附录A和附录B中提供了一系列全面的系统研究，旨在证明所提出方法的性能。<br>
在这项工作中，我们考虑一般形式的参数化和非线性偏微分方程<br>
$$u_t+\mathcal{N}[u;\lambda]=0,x\in\Omega,t\in[0,T] \tag{1}$$<br>
其中，$u(t, x)$表示隐式解（latent, hidden），$\mathcal{N}[·;\lambda]$为以$\lambda$为参数的非线性算子，$\Omega$为$\R^N$的子集。上述公式表示了数学物理中的一系列问题，包括守恒定律、扩散过程、平流-扩散-反应系统以及动力学方程等。本文以一维空间中的Burgers方程<sup id="fnref:13"><a href="#fn:13" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="C. Basdevant, M. Deville, P. Haldenwang, J. Lacroix, J. Ouazzani, R. Peyret, P. Orlandi, A. Patera, Spectral and fifinite difference solutions of the Burgers equation, Comput. Fluids 14 (1986) 23–41.
">[13]</span></a></sup>为例，其中$\mathcal{N}[u;\lambda]=\lambda_1uu_x-\lambda_2u_{xx}$、$\lambda=(\lambda_1,\lambda_2)$，下标表示对时间或空间的偏微分。考虑到系统的噪声测量，我们对以下两种情况下的解感兴趣：<br>
1.给定模型参数$\lambda$，怎样描述系统的隐态$u(t, x)$；此类问题涉及到推理、滤波、平滑或者数据驱动的偏微分方程求解<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Inferring solutions of differential equations using noisy multi-fifidelity data, J. Comput. Phys. 335 (2017) 736–746.
">[4]</span></a></sup><sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Numerical Gaussian processes for time-dependent and non-linear partial differential equations, 2017, arXiv: 1703.10230.
">[8]</span></a></sup><br>
2. 模型参数$\lambda$为何值时能够最好地描述观测数据;第二类问题涉及到学习、系统识别、数据驱动的偏微分方程反问题<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.
">[5]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.
">[9]</span></a></sup><sup id="fnref:14"><a href="#fn:14" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S.H. Rudy, S.L. Brunton, J.L. Proctor, J.N. Kutz, Data-driven discovery of partial differential equations, Sci. Adv. 3 (2017).
">[14]</span></a></sup>。</p>
<h1>3 Data-driven solutions of partial differential equations</h1>
<p>首先我们来看如何利用数据驱动的方式计算偏微分方程的解：<br>
$$u_t+\mathcal{N}[u]=0,x\in\Omega,t\in[0,T] \tag{2}$$<br>
其中，$u(t, x)$表示隐式解（latent, hidden），$\mathcal{N}[·;\lambda]$为以$\lambda$为参数的非线性算子，$\Omega$为$\R^N$的子集。在如下章节中，我们提出了两种不同的算法，分别命名连续时间模型和离散时间模型。分别通过不同的基准问题来突出它们的特性和性能。在我们研究的第二部分（下一节），我们将注意力转移到偏微分方程的数据驱动发现问题上<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.
">[5]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.
">[9]</span></a></sup><sup id="fnref:14"><a href="#fn:14" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S.H. Rudy, S.L. Brunton, J.L. Proctor, J.N. Kutz, Data-driven discovery of partial differential equations, Sci. Adv. 3 (2017).
">[14]</span></a></sup>。</p>
<h2 id="3-1-连续时间模型">3.1 连续时间模型</h2>
<p>我们定义f(t, x)由方程$2$左侧给出，即<br>
$$f:=u_t+\mathcal{N}[u] \tag{3}$$<br>
然后用神经网络逼近$u(t, x)$。这个假设和方程$3$共同构成了一个PINN $f(t, x)$。该网络可通过链式求导法则[12]，并且与网络表示$u(t, x)$具有相同的参数，尽管由于微分算子$N$的作用而具有不同的激活函数。神经网络$u(t, x)$和$f(t, x)$之间的共享参数可通过最小化均方误差（MSE）函数来学习。<br>
$$MSE = MSE_u+MSE_f\tag{4}$$<br>
其中<br>
$$MSE_u=\frac{1}{N_u}\sum_{i=1}^{N_u}\mid{u(t_{u}^{i}, x^{u}<em>{i})-u^i}\mid^2$$<br>
$$MSE_f=\frac{1}{N_f}\sum</em>{i=1}^{N_u}\mid{f(t_{f}^{i}, x^{f}_{i})}\mid^2$$</p>
<details><summary>参考文献</summary>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classifification with deep convolutional neural networks, in: Advances in Neural Information Processing Systems, 2012, pp. 1097–1105.<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">B.M. Lake, R. Salakhutdinov, J.B. Tenenbaum, Human-level concept learning through probabilistic program induction, Science 350 (2015) 1332–1338.<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">B. Alipanahi, A. Delong, M.T. Weirauch, B.J. Frey, Predicting the sequence specifificities of DNA- and RNA-binding proteins by deep learning, Nat. Biotechnol. 33 (2015) 831–838.<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Inferring solutions of differential equations using noisy multi-fifidelity data, J. Comput. Phys. 335 (2017) 736–746.<a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.<a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Owhadi, Bayesian numerical homogenization, Multiscale Model. Simul. 13 (2015) 812–828.<a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C.E. Rasmussen, C.K. Williams, Gaussian Processes for Machine Learning, vol. 1, MIT Press, Cambridge, 2006.<a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Numerical Gaussian processes for time-dependent and non-linear partial differential equations, 2017, arXiv: 1703.10230.<a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.<a href="#fnref:9" rev="footnote"> ↩</a></span></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">10.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Owhadi, C. Scovel, T. Sullivan, et al., Brittleness of Bayesian inference under fifinite information in a continuous world, Electron. J. Stat. 9 (2015) 1–79.<a href="#fnref:10" rev="footnote"> ↩</a></span></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">11.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366.<a href="#fnref:11" rev="footnote"> ↩</a></span></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">12.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A.G. Baydin, B.A. Pearlmutter, A.A. Radul, J.M. Siskind, Automatic differentiation in machine learning: a survey, 2015, arXiv:1502.05767.<a href="#fnref:12" rev="footnote"> ↩</a></span></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">13.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C. Basdevant, M. Deville, P. Haldenwang, J. Lacroix, J. Ouazzani, R. Peyret, P. Orlandi, A. Patera, Spectral and fifinite difference solutions of the Burgers equation, Comput. Fluids 14 (1986) 23–41.<a href="#fnref:13" rev="footnote"> ↩</a></span></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">14.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S.H. Rudy, S.L. Brunton, J.L. Proctor, J.N. Kutz, Data-driven discovery of partial differential equations, Sci. Adv. 3 (2017).<a href="#fnref:14" rev="footnote"> ↩</a></span></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">15.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I.E. Lagaris, A. Likas, D.I. Fotiadis, Artifificial neural networks for solving ordinary and partial differential equations, IEEE Trans. Neural Netw. 9 (1998) 987–1000.<a href="#fnref:15" rev="footnote"> ↩</a></span></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">16.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D.C. Psichogios, L.H. Ungar, A hybrid neural network-fifirst principles approach to process modeling, AIChE J. 38 (1992) 1499–1511.<a href="#fnref:16" rev="footnote"> ↩</a></span></li><li id="fn:17"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">17.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J.-X. Wang, J. Wu, J. Ling, G. Iaccarino, H. Xiao, A comprehensive physics-informed machine learning framework for predictive turbulence modeling, 2017, arXiv:1701.07102.<a href="#fnref:17" rev="footnote"> ↩</a></span></li><li id="fn:18"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">18.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Zhu, N. Zabaras, Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantifification, 2018, arXiv:1801. 06879.<a href="#fnref:18" rev="footnote"> ↩</a></span></li><li id="fn:19"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">19.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Hagge, P. Stinis, E. Yeung, A.M. Tartakovsky, Solving differential equations with unknown constitutive relations as recurrent neural networks, 2017, arXiv:1710.02242.<a href="#fnref:19" rev="footnote"> ↩</a></span></li><li id="fn:20"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">20.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Tripathy, I. Bilionis, Deep UQ: learning deep neural network surrogate models for high dimensional uncertainty quantifification, 2018, arXiv:1802. 00850.<a href="#fnref:20" rev="footnote"> ↩</a></span></li><li id="fn:21"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">21.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">P.R. Vlachas, W. Byeon, Z.Y. Wan, T.P. Sapsis, P. Koumoutsakos, Data-driven forecasting of high-dimensional chaotic systems with long-short term memory networks, 2018, arXiv:1802.07486.<a href="#fnref:21" rev="footnote"> ↩</a></span></li><li id="fn:22"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">22.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">E.J. Parish, K. Duraisamy, A paradigm for data-driven predictive modeling using field inversion and machine learning, J. Comput. Phys. 305 (2016) 758–774.<a href="#fnref:22" rev="footnote"> ↩</a></span></li><li id="fn:23"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">23.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Duraisamy, Z.J. Zhang, A.P. Singh, New approaches in turbulence and transition modeling using data-driven techniques, in: 53rd AIAA Aerospace Sciences Meeting, 2018, p. 1284.<a href="#fnref:23" rev="footnote"> ↩</a></span></li><li id="fn:24"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">24.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Ling, A. Kurzawski, J. Templeton, Reynolds averaged turbulence modelling using deep neural networks with embedded invariance, J. Fluid Mech. 807 (2016) 155–166.<a href="#fnref:24" rev="footnote"> ↩</a></span></li><li id="fn:25"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">25.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Z.J. Zhang, K. Duraisamy, Machine learning methods for data-driven turbulence modeling, in: 22nd AIAA Computational Fluid Dynamics Conference, 2015, p. 2460.<a href="#fnref:25" rev="footnote"> ↩</a></span></li><li id="fn:26"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">26.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Milano, P. Koumoutsakos, Neural network modeling for near wall turbulent flow, J. Comput. Phys. 182 (2002) 1–26.<a href="#fnref:26" rev="footnote"> ↩</a></span></li><li id="fn:27"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">27.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">P. Perdikaris, D. Venturi, G.E. Karniadakis, Multififidelity information fusion algorithms for high-dimensional systems and massive data sets, SIAM J. Sci. Comput. 38 (2016) B521–B538.<a href="#fnref:27" rev="footnote"> ↩</a></span></li><li id="fn:28"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">28.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Rico-Martinez, J. Anderson, I. Kevrekidis, Continuous-time nonlinear signal processing: a neural network based approach for gray box identification, in: Neural Networks for Signal Processing IV. Proceedings of the 1994 IEEE Workshop, IEEE, 1994, pp. 596–605.<a href="#fnref:28" rev="footnote"> ↩</a></span></li><li id="fn:29"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">29.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Ling, J. Templeton, Evaluation of machine learning algorithms for prediction of regions of high Reynolds averaged Navier Stokes uncertainty, Phys. Fluids 27 (2015) 085103.<a href="#fnref:29" rev="footnote"> ↩</a></span></li><li id="fn:30"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">30.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H.W. Lin, M. Tegmark, D. Rolnick, Why does deep and cheap learning work so well? J. Stat. Phys. 168 (2017) 1223–1247.<a href="#fnref:30" rev="footnote"> ↩</a></span></li><li id="fn:31"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">31.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Kondor, N-body networks: a covariant hierarchical neural network architecture for learning atomic potentials, 2018, arXiv:1803.01588.<a href="#fnref:31" rev="footnote"> ↩</a></span></li><li id="fn:32"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">32.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Kondor, S. Trivedi, On the generalization of equivariance and convolution in neural networks to the action of compact groups, 2018, arXiv:1802. 03690.<a href="#fnref:32" rev="footnote"> ↩</a></span></li><li id="fn:33"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">33.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Hirn, S. Mallat, N. Poilvert, Wavelet scattering regression of quantum chemical energies, Multiscale Model. Simul. 15 (2017) 827–863.<a href="#fnref:33" rev="footnote"> ↩</a></span></li><li id="fn:34"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">34.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S. Mallat, Understanding deep convolutional networks, Philos. Trans. R. Soc. A 374 (2016) 20150203.<a href="#fnref:34" rev="footnote"> ↩</a></span></li><li id="fn:35"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">35.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D.C. Liu, J. Nocedal, On the limited memory BFGS method for large scale optimization, Math. Program. 45 (1989) 503–528.<a href="#fnref:35" rev="footnote"> ↩</a></span></li><li id="fn:36"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">36.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016.<a href="#fnref:36" rev="footnote"> ↩</a></span></li><li id="fn:37"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">37.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D. Kingma, J. Ba, Adam: a method for stochastic optimization, 2014, arXiv:1412.6980.<a href="#fnref:37" rev="footnote"> ↩</a></span></li><li id="fn:38"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">38.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Choromanska, M. Henaff, M. Mathieu, G.B. Arous, Y. LeCun, The loss surfaces of multilayer networks, in: Artifificial Intelligence and Statistics, pp. 192–204.<a href="#fnref:38" rev="footnote"> ↩</a></span></li><li id="fn:39"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">39.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Shwartz-Ziv, N. Tishby, Opening the black box of deep neural networks via information, 2017, arXiv:1703.00810.<a href="#fnref:39" rev="footnote"> ↩</a></span></li><li id="fn:40"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">40.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T.A. Driscoll, N. Hale, L.N. Trefethen, Chebfun Guide, 2014.<a href="#fnref:40" rev="footnote"> ↩</a></span></li><li id="fn:41"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">41.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Stein, Large sample properties of simulations using Latin hypercube sampling, Technometrics 29 (1987) 143–151.<a href="#fnref:41" rev="footnote"> ↩</a></span></li><li id="fn:42"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">42.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Snoek, H. Larochelle, R.P. Adams, Practical bayesian optimization of machine learning algorithms, in: Advances in Neural Information Processing Systems, 2012, pp. 2951–2959.<a href="#fnref:42" rev="footnote"> ↩</a></span></li><li id="fn:43"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">43.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H.-J. Bungartz, M. Griebel, Sparse grids, Acta Numer. 13 (2004) 147–269.<a href="#fnref:43" rev="footnote"> ↩</a></span></li><li id="fn:44"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">44.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I.H. Sloan, H. Wo´zniakowski, When are quasi-Monte Carlo algorithms effiffifficient for high dimensional integrals? J. Complex. 14 (1998) 1–33.<a href="#fnref:44" rev="footnote"> ↩</a></span></li><li id="fn:45"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">45.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Iserles, A First Course in the Numerical Analysis of Differential Equations, vol. 44, Cambridge University Press, 2009.<a href="#fnref:45" rev="footnote"> ↩</a></span></li><li id="fn:46"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">46.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Von Kármán, Aerodynamics, vol. 9, McGraw-Hill, New York, 1963.<a href="#fnref:46" rev="footnote"> ↩</a></span></li><li id="fn:47"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">47.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">G. Karniadakis, S. Sherwin, Spectral/hp Element Methods for Computational Fluid Dynamics, Oxford University Press, 2013.<a href="#fnref:47" rev="footnote"> ↩</a></span></li><li id="fn:48"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">48.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Dauxois, Fermi, Pasta, Ulam and a mysterious lady, 2008, arXiv:0801.1590.<a href="#fnref:48" rev="footnote"> ↩</a></span></li><li id="fn:49"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">49.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G.S. Corrado, A. Davis, J. Dean, M. Devin, et al., Tensorflow: large-scale machine learning on heterogeneous distributed systems, 2016, arXiv:1603.04467.<a href="#fnref:49" rev="footnote"> ↩</a></span></li><li id="fn:50"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">50.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S.L. Brunton, J.L. Proctor, J.N. Kutz, Discovering governing equations from data by sparse identifification of nonlinear dynamical systems, Proc. Natl. Acad. Sci. 113 (2016) 3932–3937.<a href="#fnref:50" rev="footnote"> ↩</a></span></li></ol></div></div></details><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>shaowinw
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/" title="Physics-informed neural networks:Translation Part I">http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9C%B0%E7%90%83%E7%89%A9%E7%90%86/" rel="tag"> <i class="fa fa-tag"></i> 深度学习与计算地球物理</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/23/10.1126sciadv.aay6946/" rel="prev" title="Wave physics as an analog recurrent neural network">
      <i class="fa fa-chevron-left"></i> Wave physics as an analog recurrent neural network
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text">ABSTRACT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">3.</span> <span class="nav-text">Problem setup</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">4.</span> <span class="nav-text">3 Data-driven solutions of partial differential equations</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-连续时间模型"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 连续时间模型</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">shaowinw</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">鲁ICP备20023201号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shaowinw</span>
</div>

//

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://blog.geophyai.com/2021/05/07/10.1016j.jcp.2018.10.045_a/',]
      });
      });
  </script>

<script src="../js/src/av-min.js"></script>
<script src="../js/src/valine.min.js"></script>
<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/gh//AshinWang/SimpleValine/SimpleValine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xGkAfNjiLy2iAFwuv2Itmye6-gzGzoHsz',
      appKey     : 'IGOUrFEiKTeXfsDJwsmNLMnd',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
