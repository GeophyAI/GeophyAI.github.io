<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans SC:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Courier New:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.geophyai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Physics-informed neural networks翻译Part II">
<meta property="og:type" content="article">
<meta property="og:title" content="Physics-informed neural networks:Translation Part II">
<meta property="og:url" content="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/index.html">
<meta property="og:site_name" content="GeophyAI">
<meta property="og:description" content="Physics-informed neural networks翻译Part II">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/fig03.png">
<meta property="article:published_time" content="2021-05-14T03:10:46.000Z">
<meta property="article:modified_time" content="2021-05-14T03:10:46.000Z">
<meta property="article:author" content="shaowinw">
<meta property="article:tag" content="深度学习与计算地球物理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/fig03.png">

<link rel="canonical" href="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Physics-informed neural networks:Translation Part II | GeophyAI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">GeophyAI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能与地球物理数据处理</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="shaowinw">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeophyAI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Physics-informed neural networks:Translation Part II
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-14 11:10:46" itemprop="dateCreated datePublished" datetime="2021-05-14T11:10:46+08:00">2021-05-14</time>
            </span>


	
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">文献翻译</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/05/14/10.1016j.jcp.2018.10.045_b/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/05/14/10.1016j.jcp.2018.10.045_b/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">Physics-informed neural networks翻译Part II</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>原文地址：<a href="https://www.sciencedirect.com/science/article/pii/S0021999118307125" target="_blank" rel="noopener">PINN：深度学习框架下求解含有非线性偏微分方程的正问题、反问题</a><br>
doi:<a href="http://sci-hub.ren/10.1016/j.jcp.2018.10.045" target="_blank" rel="noopener">10.1016/j.jcp.2018.10.045</a></p>
<h1>Data-driven discovery of partial differential equations</h1>
<p>在我们研究的当前部分，我们将注意力转移到数据驱动的偏微分方程发现问题上<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.
">[5]</span></a></sup><sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.
">[9]</span></a></sup><sup id="fnref:14"><a href="#fn:14" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="S.H. Rudy, S.L. Brunton, J.L. Proctor, J.N. Kutz, Data-driven discovery of partial differential equations, Sci. Adv. 3 (2017).
">[14]</span></a></sup>。在第$4.1$节和第$4.2$节中，我们提出了两种不同类型的算法，即连续时间模型和离散时间模型，并通过各种规范问题(canonical problems)的视角强调了它们的性质和性能。</p>
<h1>4.1 连续时间模型</h1>
<p>首先，让我们回忆方程$1$并和$3.1$节相类似定义$f(t,x)$由公式$1$左侧给定，即<br>
$$f:=u_t+\mathcal{N}[u:\lambda]\tag{14}$$<br>
我们继续使用深度神经网络近似$u(t, x)$。此假设以及公式$14$构建了一个PINN。该网络可以通过使用自动微分来对方程的不同部分应用链式法则推导出来<sup id="fnref:12"><a href="#fn:12" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="A.G. Baydin, B.A. Pearlmutter, A.A. Radul, J.M. Siskind, Automatic differentiation in machine learning: a survey, 2015, arXiv:1502.05767.
">[12]</span></a></sup>。值得注意的是，微分算子$\lambda$的参数变味了PINN$f(t,x)$的参数。</p>
<h2 id="4-1-1-例子（Naiver-Stokes方程）">4.1.1 例子（Naiver-Stokes方程）</h2>
<p>我们的下一个例子涉及到不可压缩流体流动的现实场景，由无处不在的Navier-Stokes方程所描述。Naiver-Stokes方程描述了许多具有科学和工程意义的物理现象。它们可以用来模拟天气、洋流、管道中的水流和机翼周围的气流。完整和简化的Navier-Stokes方程有助于飞机和汽车的设计、血液流动的研究、电站的设计、污染物扩散的分析以及许多其他应用。让我们考虑二维的Navier-Stokes方程：<br>
$$ u_t+\lambda_1(uu_x+vu_y)=-p_x+\lambda_2(u_{xx}+u_{yy}) $$<br>
$$ v_t+\lambda_1(uv_x+uv_y)=-p_y+\lambda_2(v_{xx}+v_{yy}) \tag{15}$$<br>
其中，$u(t, x, y)$表示速度场的$x$分量，$v(t, x, y)$表示速度场$y$分量，$p(t, x, y)$表示压力。$\lambda=(\lambda_1, \lambda_2)$为未知参数。通过在无散度函数集合中搜索$Naiver-Stokes$方程的解，即：<br>
$$u_x+v_y=0\tag{16}$$<br>
这个额外的方程是描述流体质量守恒的不可压缩流体的连续性方程。我们假设<br>
$$u=\psi_y, v=-\psi_x$$<br>
$\psi(t, x, y)$为隐函数。在此假设下，能够自动满足连续方程$16$。给定速度场的噪声测量<br>
$$\lbrace t^i, x^i, y^i, u^i, v^i\rbrace^N_{i=1}$$<br>
我们希望学习到参数$\lambda$以及压力场$p(t, x, y)$。<br>
定义$f(t, x, y)$和$g(t, x, y)$为：<br>
$$f:=u_t+\lambda_1(uu_x+vu_y)+p_x-\lambda_2(u_{xx}+u_{yy})$$<br>
$$g:=v_t+\lambda_1(uv_x+vv_y)+p_y-\lambda_2(v_{xx}+v_{yy})$$<br>
然后使用有两个输出的神经网络近似$[\psi(t, x, y) p(t, x, y)]$。此先验假设以及公式$17$、$18$构成了PINN网络$[f(t, x, y) g(t, x, y)]$。$Navier-Stokes$算子的参数$\lambda$以及神经网络$[\psi(t, x, y), p(t, x, y)]$和$[f(t, x, y), g(t, x, y)]$的参数可以通过最小化均方误差函数$19$来训练得到。<br>
$$MSE:=\frac{1}{N} \sum_{i=1}^N(\mid u(t^i, x^i, y^i)-u^i \mid^2+\mid v(t^i, x^i, y^i)-v^i\mid^2)+\frac{1}N \sum_{i=1}^N(\mid f(t^i, x^i, y^i)\mid^2+\mid g(t^i, x^i, y^i)\mid ^2) \tag{19}$$<br>
这里我们讨论不可压缩流体通过圆柱体的问题，aproblem known to exhibit rich dynamic behavior and transitions for different regimes of theReynolds number $Re=u_\infty D/v$。假设一个无量纲自由流体速度为$u_\infty=1$,圆柱直径$D=1$，运动黏度$v=0.01$，该系统呈现周期性稳态行为，其特征是圆柱wake中的不对称涡旋脱落模式，即$Karman vortex street$<sup id="fnref:46"><a href="#fn:46" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="T. Von Kármán, Aerodynamics, vol. 9, McGraw-Hill, New York, 1963.
">[46]</span></a></sup>。<br>
为生成针对该问题的高分辨率数据集，我们采用了光谱/hp元素求解器$NekTar$<sup id="fnref:47"><a href="#fn:47" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="G. Karniadakis, S. Sherwin, Spectral/hp Element Methods for Computational Fluid Dynamics, Oxford University Press, 2013.
">[47]</span></a></sup>。具体来说，将解空间在空间域离散为包含412个三角形元素的曲面细分，在每个元素中，解都被近似为十阶分层半正交$Jacobi$多项式展开式的线性组合。我们假设左边界有均匀的自由流体速度剖面，在圆柱体下游25直径处的右边界施加零压力流出条件，并在上下边界$[-15, 25]\times[-8, 8]$的区域添加周期边界条件。我们是用三阶刚性稳定方法对公式$15$进行积分，直到该系统达到周期稳定状态，如图3(a)所示。在接下来的内容中，与这个稳态解相对应的数据集的一小部分将被用于模型训练，而剩余数据则用于模型预测。为简单起见，我们选择将采样限制在圆柱体下游的矩形区域，如图3(a)所示。<br>
<img src="/2021/05/14/10.1016j.jcp.2018.10.045_b/fig03.png" alt="fig03"><br>
给定动沿流向$u(t, x, y)$和横向$v(t, x , y)$速度分量上的散射和势噪声数据，我们的目标是确定未知参数$\lambda_1$和$\lambda_2$，并定性地、准确地重建圆柱wake中的整个压力场$p(t, x, y)$，该场只能被识别为常数。为此，我们随机从高分辨率数据中进行降采样来得到训练数据。为了突出我们的方法在散射和稀疏数据中的学习能力，我们选取了$N=5,000$。仅相当于图3(b)所示的可用数据总数1%的数据。此外，我们还绘制了模型训练后预测速度分量$u(t, x, y)$和$v(t, x, y)$的代表性快照。这里使用的神经网络包含9层，每层20个神经元。<br>
此例子结果的总结如图4所示。我们发现，即使训练数据中有非常多的噪声，PINN依旧能够非常准确地确定未知参数$\lambda_1$、$\lambda_2$。具体来说，对于无噪声的训练数据，估计误差$\lambda_1$和$\lambda_2$分别为$0.078%$和$4.67%$。当训练数据中包含$1%$的不相关高斯噪声时，预测仍然是鲁棒的，两系数的预测误差分别为$0.17%$和$5.70%$。<br>
一个更有趣的结果来自于该网络在没有任何关于压力本身的训练数据的情况下对整个压力场$p(t, x, y)$的高精度定性预测能力。与精确压力场的对比如图4所示。精确压力场和预测压力场之间的大小差异是由不可压缩Navier–Stokes系统的本质所决定的，因为压力场只有在一个常数以内才可被识别。通过利用基础物理从辅助测量值中推断出感兴趣的连续变量值，这是PINN所提供的更强能力的表现，展示了它们在求解高维度反问题中的潜力。<br>
到目前为止，我们均假设数据点在整个时空域中可用。在许多实际情况下，人们可能只能在不同的时刻观察系统。在下一节中，我们将介绍一种不同的方法，该方法仅使用两个数据快照来解决数据驱动的发现问题。我们将看到，通过利用经典的Runge-Kutta时间递推方案，人们可以构建离散时间的PINN，即使数据快照之间的时间间隔非常大，其也可以保持较高的预测精度。</p>
<h1>4.2 离散时间模型</h1>
<p>对公式$1$应用$q$阶Runge-Kutta方法得到以下公式<br>
$$u^{n+c_i}=u^n-\Delta t \sum_{j=1}^qa_ij \mathcal{N}[u^{n+c_j}; \lambda], i=1,…,q,$$<br>
$$u^{n+1}=u^{n}-\Delta t \sum_{j=1}^{q}b_j \mathcal{N}[u^{n+c_j};\lambda] \tag{20}$$<br>
其中，$u^{n+c_j}(x)=u(t^n+c_j\Delta t, x)$是系统在$t^n+c_j$($j=1,…,q$)时刻的隐藏状态。该通用形式包含了显式和隐式的时间递推格式，该格式取决于参数$\lbrace {a_ij, b_j, c_j}\rbrace$的选取。公式$20$可等价为：<br>
$$u^n=u_i^n, i=1…,q,\<br>
u^{n+1}=u_i^{n+1},i=1,…,q \tag{21}<br>
$$<br>
其中<br>
$$u_i^n:=u^{n+c_i}+\Delta t \sum_{j=1}^{q}a_{ij}\mathcal{N}[c^{n+c_j};\lambda],i=1,…,q,$$<br>
$$u_i^{n+1}:=u^{n+c_i}+\Delta t \sum_{j=1}^{q}(a_ij-b_j) \mathcal{N}[u^{n+c_j};\lambda], i=1,…,q \tag{22}$$<br>
将多输出神经网络置于<br>
$$[u^{n+c_1}(x),…,u^{n+c_q}(x)] \tag{23}$$<br>
之前，<br>
先验假设以及公式$22$形成了两个PINN：<br>
$$[u_1^n(x),…,u_q^n(x), u_{q+1}^n(x)] \tag{24}$$<br>
以及<br>
$$[u_1^{n+1}(x),…,u_q^{n+1}(x),u_{q+1}^{n+1}(x)] \tag{25}$$<br>
给定两个不同时刻$t^n$和$t^{n+1}$的时间切片$\lbrace \bold x^n, \bold u^n \rbrace$和$\lbrace \bold x^{n+1}, \bold u^{n+1} \rbrace$，神经网络$23$、$24$和$25$的共享参数以及微分算子的参数$\lambda$可以通过最小化平方误差$26$得到。<br>
$$SSE=SSE_n+SSE_n+1 \tag{26}$$<br>
其中<br>
$$SSE_n:=\sum_{j=1}^q \sum_{i=1}^{N_n}  \mid u_j^n(x^{n, i})-u^{n, i}\mid^2$$<br>
$$SSE_{n+1}:=\sum_{j=1}^n \sum_{i=1}^{N_{n+1}} \mid u_j^{n+1}(x^{n+1,i}-u^{n+1,i})\mid ^2$$<br>
$$x^n=\lbrace x^{n,i} \rbrace _{i=1}^{N_n}, u^n=\lbrace u^{n, i} \rbrace _{i=1}^{N_n}$$</p>
<h3 id="4-2-1-例子">4.2.1 例子</h3>
<p>我们的最后一个例子旨在强调所提出的框架在处理涉及高阶导数的偏微分方程的能力。这里，我们考虑浅水表面上波浪的数学模型；$Korteweg–de Vries(KdV)$方程。这个方程也可以看作是带有dispersive项的Burgers方程。KdV方程与物理问题有几方面联系：它描述了长一维波在许多物理环境中的演化。这种物理环境包括具有弱非线性恢复力的浅水波、密度分层海洋中的长内波（long internal waves）、等离子体中的离子声波和晶格上的声波。此外，$KdV$方程是连续极限下$Fermi-Pasta-Ulam$问题<sup id="fnref:48"><a href="#fn:48" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="T. Dauxois, Fermi, Pasta, Ulam and a mysterious lady, 2008, arXiv:0801.1590.
">[48]</span></a></sup>中弦的控制方程。$KdV$公式如下:<br>
$$u_t+\lambda_1uu_x+\lambda_2u_{xxx} = 0 \tag{27}$$<br>
$(\lambda_1, \lambda_2)$为未知参数。对于KdV方程，公式$22$中的非线性算子由以下公式给定：<br>
$$\mathcal{N}[u^{n+c_j}]=\lambda_1 u^{n+c_j}u_x^{n+c_j}-\lambda_2u_{xxx}^{n+c_j}$$<br>
公式$23$、$24$、$25$的共享参数以及KdV方程的参数$\lambda=(\lambda_1, \lambda_2)可以ton过最小化平方误差公式$26$得到。<br>
我们通过使用传统谱方法模拟公式$27$来得到训练数据和测试数据。具体来讲，初始边界条件为$u(0, x)=cos(\pi x)$以及周期性边界条件，使用$Chebfun$包以512个modes的谱傅里叶离散以及四阶显式$Runge-Kutta$时间积分器以离散时间步长$\Delta t=10^{-6}$对公式$27$积分到$t=1.0$。利用该数据集，我们提取$t^n=0.2$和$t^{n+1}=0.8$的两个解的切片，并使用$N_n=199$和$N_{n+1}=201$对其进行随机降采样来生成训练集。然后我们利用这些数据来训练离散时间PINN，loss函数平方误差为$26$，优化器为L-BFGS<sup id="fnref:35"><a href="#fn:35" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="D.C. Liu, J. Nocedal, On the limited memory BFGS method for large scale optimization, Math. Program. 45 (1989) 503–528.
">[35]</span></a></sup>。网络架构包括4个隐藏层，每层有50个神经元，以及一个用于预测q阶Runge-Kutta解（即$u^{n+c_j}(x)$）的输出层（$j=1,…,q$）其中，q是生成及其精度阶时间误差累积的经验值，其由以下公式决定：<br>
$$q=0.5log\epsilon /log(\Delta t)$$<br>
该例子的时间步长为$\Delta t = 0.6$。<br>
实验结果如图5所示。在顶部图例中，我们给出了精确解$u(t, x)$，以及用于训练的两个数据快照的位置。在中间的图例中给出了精确解和训练数据的更详细的概述。方程$27$的复杂非线性动力学是如何导致两个快照之间的解的形式存在显著差异的是需要我们注意的地方。尽管存在这些差异，并且两个训练快照之间存在较大的时间间隔，但是无论训练数据是否被噪声破坏，我们的方法都能够正确确定未知参数。具体来说，对于无噪声的训练数据，估计误差$\lambda_1$和$\lambda_2$分别为$0.023%$和$0.006%$，而训练数据中噪声为$1%$的情况返回的误差分别为$0.057%$和$0.017%$。</p>
<details><summary>参考文献</summary>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classifification with deep convolutional neural networks, in: Advances in Neural Information Processing Systems, 2012, pp. 1097–1105.<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">B.M. Lake, R. Salakhutdinov, J.B. Tenenbaum, Human-level concept learning through probabilistic program induction, Science 350 (2015) 1332–1338.<a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">B. Alipanahi, A. Delong, M.T. Weirauch, B.J. Frey, Predicting the sequence specifificities of DNA- and RNA-binding proteins by deep learning, Nat. Biotechnol. 33 (2015) 831–838.<a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Inferring solutions of differential equations using noisy multi-fifidelity data, J. Comput. Phys. 335 (2017) 736–746.<a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Machine learning of linear differential equations using Gaussian processes, J. Comput. Phys. 348 (2017) 683–693.<a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Owhadi, Bayesian numerical homogenization, Multiscale Model. Simul. 13 (2015) 812–828.<a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C.E. Rasmussen, C.K. Williams, Gaussian Processes for Machine Learning, vol. 1, MIT Press, Cambridge, 2006.<a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, P. Perdikaris, G.E. Karniadakis, Numerical Gaussian processes for time-dependent and non-linear partial differential equations, 2017, arXiv: 1703.10230.<a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Raissi, G.E. Karniadakis, Hidden physics models: machine learning of nonlinear partial differential equations, 2017, arXiv:1708.00588.<a href="#fnref:9" rev="footnote"> ↩</a></span></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">10.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H. Owhadi, C. Scovel, T. Sullivan, et al., Brittleness of Bayesian inference under fifinite information in a continuous world, Electron. J. Stat. 9 (2015) 1–79.<a href="#fnref:10" rev="footnote"> ↩</a></span></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">11.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366.<a href="#fnref:11" rev="footnote"> ↩</a></span></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">12.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A.G. Baydin, B.A. Pearlmutter, A.A. Radul, J.M. Siskind, Automatic differentiation in machine learning: a survey, 2015, arXiv:1502.05767.<a href="#fnref:12" rev="footnote"> ↩</a></span></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">13.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">C. Basdevant, M. Deville, P. Haldenwang, J. Lacroix, J. Ouazzani, R. Peyret, P. Orlandi, A. Patera, Spectral and fifinite difference solutions of the Burgers equation, Comput. Fluids 14 (1986) 23–41.<a href="#fnref:13" rev="footnote"> ↩</a></span></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">14.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S.H. Rudy, S.L. Brunton, J.L. Proctor, J.N. Kutz, Data-driven discovery of partial differential equations, Sci. Adv. 3 (2017).<a href="#fnref:14" rev="footnote"> ↩</a></span></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">15.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I.E. Lagaris, A. Likas, D.I. Fotiadis, Artifificial neural networks for solving ordinary and partial differential equations, IEEE Trans. Neural Netw. 9 (1998) 987–1000.<a href="#fnref:15" rev="footnote"> ↩</a></span></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">16.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D.C. Psichogios, L.H. Ungar, A hybrid neural network-fifirst principles approach to process modeling, AIChE J. 38 (1992) 1499–1511.<a href="#fnref:16" rev="footnote"> ↩</a></span></li><li id="fn:17"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">17.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J.-X. Wang, J. Wu, J. Ling, G. Iaccarino, H. Xiao, A comprehensive physics-informed machine learning framework for predictive turbulence modeling, 2017, arXiv:1701.07102.<a href="#fnref:17" rev="footnote"> ↩</a></span></li><li id="fn:18"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">18.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Y. Zhu, N. Zabaras, Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantifification, 2018, arXiv:1801. 06879.<a href="#fnref:18" rev="footnote"> ↩</a></span></li><li id="fn:19"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">19.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Hagge, P. Stinis, E. Yeung, A.M. Tartakovsky, Solving differential equations with unknown constitutive relations as recurrent neural networks, 2017, arXiv:1710.02242.<a href="#fnref:19" rev="footnote"> ↩</a></span></li><li id="fn:20"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">20.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Tripathy, I. Bilionis, Deep UQ: learning deep neural network surrogate models for high dimensional uncertainty quantifification, 2018, arXiv:1802. 00850.<a href="#fnref:20" rev="footnote"> ↩</a></span></li><li id="fn:21"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">21.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">P.R. Vlachas, W. Byeon, Z.Y. Wan, T.P. Sapsis, P. Koumoutsakos, Data-driven forecasting of high-dimensional chaotic systems with long-short term memory networks, 2018, arXiv:1802.07486.<a href="#fnref:21" rev="footnote"> ↩</a></span></li><li id="fn:22"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">22.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">E.J. Parish, K. Duraisamy, A paradigm for data-driven predictive modeling using field inversion and machine learning, J. Comput. Phys. 305 (2016) 758–774.<a href="#fnref:22" rev="footnote"> ↩</a></span></li><li id="fn:23"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">23.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">K. Duraisamy, Z.J. Zhang, A.P. Singh, New approaches in turbulence and transition modeling using data-driven techniques, in: 53rd AIAA Aerospace Sciences Meeting, 2018, p. 1284.<a href="#fnref:23" rev="footnote"> ↩</a></span></li><li id="fn:24"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">24.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Ling, A. Kurzawski, J. Templeton, Reynolds averaged turbulence modelling using deep neural networks with embedded invariance, J. Fluid Mech. 807 (2016) 155–166.<a href="#fnref:24" rev="footnote"> ↩</a></span></li><li id="fn:25"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">25.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Z.J. Zhang, K. Duraisamy, Machine learning methods for data-driven turbulence modeling, in: 22nd AIAA Computational Fluid Dynamics Conference, 2015, p. 2460.<a href="#fnref:25" rev="footnote"> ↩</a></span></li><li id="fn:26"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">26.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Milano, P. Koumoutsakos, Neural network modeling for near wall turbulent flow, J. Comput. Phys. 182 (2002) 1–26.<a href="#fnref:26" rev="footnote"> ↩</a></span></li><li id="fn:27"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">27.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">P. Perdikaris, D. Venturi, G.E. Karniadakis, Multififidelity information fusion algorithms for high-dimensional systems and massive data sets, SIAM J. Sci. Comput. 38 (2016) B521–B538.<a href="#fnref:27" rev="footnote"> ↩</a></span></li><li id="fn:28"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">28.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Rico-Martinez, J. Anderson, I. Kevrekidis, Continuous-time nonlinear signal processing: a neural network based approach for gray box identification, in: Neural Networks for Signal Processing IV. Proceedings of the 1994 IEEE Workshop, IEEE, 1994, pp. 596–605.<a href="#fnref:28" rev="footnote"> ↩</a></span></li><li id="fn:29"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">29.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Ling, J. Templeton, Evaluation of machine learning algorithms for prediction of regions of high Reynolds averaged Navier Stokes uncertainty, Phys. Fluids 27 (2015) 085103.<a href="#fnref:29" rev="footnote"> ↩</a></span></li><li id="fn:30"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">30.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H.W. Lin, M. Tegmark, D. Rolnick, Why does deep and cheap learning work so well? J. Stat. Phys. 168 (2017) 1223–1247.<a href="#fnref:30" rev="footnote"> ↩</a></span></li><li id="fn:31"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">31.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Kondor, N-body networks: a covariant hierarchical neural network architecture for learning atomic potentials, 2018, arXiv:1803.01588.<a href="#fnref:31" rev="footnote"> ↩</a></span></li><li id="fn:32"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">32.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Kondor, S. Trivedi, On the generalization of equivariance and convolution in neural networks to the action of compact groups, 2018, arXiv:1802. 03690.<a href="#fnref:32" rev="footnote"> ↩</a></span></li><li id="fn:33"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">33.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Hirn, S. Mallat, N. Poilvert, Wavelet scattering regression of quantum chemical energies, Multiscale Model. Simul. 15 (2017) 827–863.<a href="#fnref:33" rev="footnote"> ↩</a></span></li><li id="fn:34"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">34.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S. Mallat, Understanding deep convolutional networks, Philos. Trans. R. Soc. A 374 (2016) 20150203.<a href="#fnref:34" rev="footnote"> ↩</a></span></li><li id="fn:35"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">35.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D.C. Liu, J. Nocedal, On the limited memory BFGS method for large scale optimization, Math. Program. 45 (1989) 503–528.<a href="#fnref:35" rev="footnote"> ↩</a></span></li><li id="fn:36"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">36.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016.<a href="#fnref:36" rev="footnote"> ↩</a></span></li><li id="fn:37"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">37.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">D. Kingma, J. Ba, Adam: a method for stochastic optimization, 2014, arXiv:1412.6980.<a href="#fnref:37" rev="footnote"> ↩</a></span></li><li id="fn:38"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">38.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Choromanska, M. Henaff, M. Mathieu, G.B. Arous, Y. LeCun, The loss surfaces of multilayer networks, in: Artifificial Intelligence and Statistics, pp. 192–204.<a href="#fnref:38" rev="footnote"> ↩</a></span></li><li id="fn:39"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">39.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">R. Shwartz-Ziv, N. Tishby, Opening the black box of deep neural networks via information, 2017, arXiv:1703.00810.<a href="#fnref:39" rev="footnote"> ↩</a></span></li><li id="fn:40"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">40.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T.A. Driscoll, N. Hale, L.N. Trefethen, Chebfun Guide, 2014.<a href="#fnref:40" rev="footnote"> ↩</a></span></li><li id="fn:41"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">41.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Stein, Large sample properties of simulations using Latin hypercube sampling, Technometrics 29 (1987) 143–151.<a href="#fnref:41" rev="footnote"> ↩</a></span></li><li id="fn:42"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">42.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">J. Snoek, H. Larochelle, R.P. Adams, Practical bayesian optimization of machine learning algorithms, in: Advances in Neural Information Processing Systems, 2012, pp. 2951–2959.<a href="#fnref:42" rev="footnote"> ↩</a></span></li><li id="fn:43"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">43.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">H.-J. Bungartz, M. Griebel, Sparse grids, Acta Numer. 13 (2004) 147–269.<a href="#fnref:43" rev="footnote"> ↩</a></span></li><li id="fn:44"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">44.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">I.H. Sloan, H. Wo´zniakowski, When are quasi-Monte Carlo algorithms effiffifficient for high dimensional integrals? J. Complex. 14 (1998) 1–33.<a href="#fnref:44" rev="footnote"> ↩</a></span></li><li id="fn:45"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">45.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">A. Iserles, A First Course in the Numerical Analysis of Differential Equations, vol. 44, Cambridge University Press, 2009.<a href="#fnref:45" rev="footnote"> ↩</a></span></li><li id="fn:46"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">46.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Von Kármán, Aerodynamics, vol. 9, McGraw-Hill, New York, 1963.<a href="#fnref:46" rev="footnote"> ↩</a></span></li><li id="fn:47"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">47.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">G. Karniadakis, S. Sherwin, Spectral/hp Element Methods for Computational Fluid Dynamics, Oxford University Press, 2013.<a href="#fnref:47" rev="footnote"> ↩</a></span></li><li id="fn:48"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">48.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">T. Dauxois, Fermi, Pasta, Ulam and a mysterious lady, 2008, arXiv:0801.1590.<a href="#fnref:48" rev="footnote"> ↩</a></span></li><li id="fn:49"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">49.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G.S. Corrado, A. Davis, J. Dean, M. Devin, et al., Tensorflow: large-scale machine learning on heterogeneous distributed systems, 2016, arXiv:1603.04467.<a href="#fnref:49" rev="footnote"> ↩</a></span></li><li id="fn:50"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">50.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">S.L. Brunton, J.L. Proctor, J.N. Kutz, Discovering governing equations from data by sparse identifification of nonlinear dynamical systems, Proc. Natl. Acad. Sci. 113 (2016) 3932–3937.<a href="#fnref:50" rev="footnote"> ↩</a></span></li></ol></div></div></details><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>shaowinw
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/" title="Physics-informed neural networks:Translation Part II">http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9C%B0%E7%90%83%E7%89%A9%E7%90%86/" rel="tag"> <i class="fa fa-tag"></i> 深度学习与计算地球物理</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/05/07/10.1016j.jcp.2018.10.045_a/" rel="prev" title="Physics-informed neural networks:Translation Part I">
      <i class="fa fa-chevron-left"></i> Physics-informed neural networks:Translation Part I
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text">Data-driven discovery of partial differential equations</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">2.</span> <span class="nav-text">4.1 连续时间模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-1-例子（Naiver-Stokes方程）"><span class="nav-number">2.1.</span> <span class="nav-text">4.1.1 例子（Naiver-Stokes方程）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#"><span class="nav-number">3.</span> <span class="nav-text">4.2 离散时间模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-例子"><span class="nav-number">3.0.1.</span> <span class="nav-text">4.2.1 例子</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">shaowinw</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">鲁ICP备20023201号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shaowinw</span>
</div>

//

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://blog.geophyai.com/2021/05/14/10.1016j.jcp.2018.10.045_b/',]
      });
      });
  </script>

<script src="../js/src/av-min.js"></script>
<script src="../js/src/valine.min.js"></script>
<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('https://cdn.jsdelivr.net/gh//AshinWang/SimpleValine/SimpleValine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'xGkAfNjiLy2iAFwuv2Itmye6-gzGzoHsz',
      appKey     : 'IGOUrFEiKTeXfsDJwsmNLMnd',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
